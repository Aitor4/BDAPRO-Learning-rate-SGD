objc[3270]: Class JavaLaunchHelper is implemented in both /Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/bin/java (0x106d8f4c0) and /Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/jre/lib/libinstrument.dylib (0x1076194e0). One of the two will be used. Which one is undefined.
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
18/02/26 22:04:44 INFO SparkContext: Running Spark version 2.0.0
18/02/26 22:04:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/02/26 22:04:45 INFO SecurityManager: Changing view acls to: Aitor
18/02/26 22:04:45 INFO SecurityManager: Changing modify acls to: Aitor
18/02/26 22:04:45 INFO SecurityManager: Changing view acls groups to: 
18/02/26 22:04:45 INFO SecurityManager: Changing modify acls groups to: 
18/02/26 22:04:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Aitor); groups with view permissions: Set(); users  with modify permissions: Set(Aitor); groups with modify permissions: Set()
18/02/26 22:04:46 INFO Utils: Successfully started service 'sparkDriver' on port 52042.
18/02/26 22:04:46 INFO SparkEnv: Registering MapOutputTracker
18/02/26 22:04:46 INFO SparkEnv: Registering BlockManagerMaster
18/02/26 22:04:46 INFO DiskBlockManager: Created local directory at /private/var/folders/04/1m8vd7011dn7rc671175zs0h0000gn/T/blockmgr-1e34e350-0237-45cc-86c4-f30ac32119af
18/02/26 22:04:46 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
18/02/26 22:04:47 INFO SparkEnv: Registering OutputCommitCoordinator
18/02/26 22:04:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/02/26 22:04:47 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.2.140:4040
18/02/26 22:04:47 INFO Executor: Starting executor ID driver on host localhost
18/02/26 22:04:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52043.
18/02/26 22:04:47 INFO NettyBlockTransferService: Server created on 192.168.2.140:52043
18/02/26 22:04:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.2.140, 52043)
18/02/26 22:04:47 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.2.140:52043 with 912.3 MB RAM, BlockManagerId(driver, 192.168.2.140, 52043)
18/02/26 22:04:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.2.140, 52043)
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.4978244780010825
Loss in iteration 3 : 0.4351386483976286
Loss in iteration 4 : 0.40674491637348903
Loss in iteration 5 : 0.3913223419068483
Loss in iteration 6 : 0.3820278446846951
Loss in iteration 7 : 0.3760193354445869
Loss in iteration 8 : 0.3719210883157191
Loss in iteration 9 : 0.3689973119135778
Loss in iteration 10 : 0.36682601719254154
Loss in iteration 11 : 0.3651524175870062
Loss in iteration 12 : 0.363816516248767
Loss in iteration 13 : 0.3627146920453644
Loss in iteration 14 : 0.3617781510531289
Loss in iteration 15 : 0.3609602849693225
Loss in iteration 16 : 0.3602289782091225
Loss in iteration 17 : 0.35956178215938905
Loss in iteration 18 : 0.3589428099905913
Loss in iteration 19 : 0.35836069517606844
Loss in iteration 20 : 0.35780722459453906
Testing accuracy  of updater 0 on alg 0 with rate 10.0 = 0.9063948100092678, training accuracy 0.8736456076012669, time elapsed: 9769 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6681732467162712
Loss in iteration 3 : 0.6455860126643476
Loss in iteration 4 : 0.6251404292546504
Loss in iteration 5 : 0.606611446190983
Loss in iteration 6 : 0.5897947755330573
Loss in iteration 7 : 0.5745066236248743
Loss in iteration 8 : 0.560582736814082
Loss in iteration 9 : 0.5478770354575658
Loss in iteration 10 : 0.5362600404894283
Loss in iteration 11 : 0.5256172358076803
Loss in iteration 12 : 0.5158474609605702
Loss in iteration 13 : 0.5068613919428221
Loss in iteration 14 : 0.49858014169419496
Loss in iteration 15 : 0.4909339939947884
Loss in iteration 16 : 0.4838612728096247
Loss in iteration 17 : 0.47730734199478037
Loss in iteration 18 : 0.47122372625571424
Loss in iteration 19 : 0.4655673423111458
Loss in iteration 20 : 0.46029982861770635
Testing accuracy  of updater 0 on alg 0 with rate 1.0 = 0.906527207732027, training accuracy 0.8678113018836473, time elapsed: 6856 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6905932056894033
Loss in iteration 3 : 0.688064261359736
Loss in iteration 4 : 0.6855600942480505
Loss in iteration 5 : 0.6830804525577548
Loss in iteration 6 : 0.680625086053545
Loss in iteration 7 : 0.6781937460946008
Loss in iteration 8 : 0.6757861856660442
Loss in iteration 9 : 0.6734021594086829
Loss in iteration 10 : 0.6710414236470604
Loss in iteration 11 : 0.668703736415893
Loss in iteration 12 : 0.666388857484858
Loss in iteration 13 : 0.664096548381859
Loss in iteration 14 : 0.6618265724147225
Loss in iteration 15 : 0.6595786946914257
Loss in iteration 16 : 0.6573526821388415
Loss in iteration 17 : 0.6551483035200966
Loss in iteration 18 : 0.6529653294505049
Loss in iteration 19 : 0.6508035324121988
Loss in iteration 20 : 0.6486626867674286
Testing accuracy  of updater 0 on alg 0 with rate 0.09999999999999998 = 0.906527207732027, training accuracy 0.8666444407401234, time elapsed: 6099 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.4978244780010825
Loss in iteration 3 : 0.38220518163786527
Loss in iteration 4 : 0.37268801728078316
Loss in iteration 5 : 0.4047366709683664
Loss in iteration 6 : 0.44321557438914766
Loss in iteration 7 : 0.47387755533585957
Loss in iteration 8 : 0.4918072586217946
Loss in iteration 9 : 0.4960770543316784
Loss in iteration 10 : 0.48761001669000503
Loss in iteration 11 : 0.46843794604020284
Loss in iteration 12 : 0.4415891600211734
Loss in iteration 13 : 0.41126324549059695
Loss in iteration 14 : 0.38294286902988334
Loss in iteration 15 : 0.3627626576703313
Loss in iteration 16 : 0.35527627447454024
Loss in iteration 17 : 0.3600310169185139
Loss in iteration 18 : 0.3700451077053155
Loss in iteration 19 : 0.3751497496453086
Loss in iteration 20 : 0.36859413053639245
Testing accuracy  of updater 1 on alg 0 with rate 10.0 = 0.9012312988216603, training accuracy 0.8786464410735122, time elapsed: 6978 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6681732467162712
Loss in iteration 3 : 0.6252482158518717
Loss in iteration 4 : 0.5734232715844564
Loss in iteration 5 : 0.5212974268223356
Loss in iteration 6 : 0.4750702150275234
Loss in iteration 7 : 0.43783267834446093
Loss in iteration 8 : 0.410092199251551
Loss in iteration 9 : 0.3908349782033267
Loss in iteration 10 : 0.3784532669186858
Loss in iteration 11 : 0.37129856685467316
Loss in iteration 12 : 0.36792585354658913
Loss in iteration 13 : 0.3671622238133997
Loss in iteration 14 : 0.3680966943005685
Loss in iteration 15 : 0.3700423400443712
Loss in iteration 16 : 0.37249351639475137
Loss in iteration 17 : 0.3750868713630551
Loss in iteration 18 : 0.37756871004451287
Loss in iteration 19 : 0.3797688027247005
Loss in iteration 20 : 0.3815798505804757
Testing accuracy  of updater 1 on alg 0 with rate 1.0 = 0.906527207732027, training accuracy 0.8694782463743957, time elapsed: 7227 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6905932056894033
Loss in iteration 3 : 0.6857877015145996
Loss in iteration 4 : 0.6790406259047483
Loss in iteration 5 : 0.6706598311121449
Loss in iteration 6 : 0.6609434448030634
Loss in iteration 7 : 0.6501739740625438
Loss in iteration 8 : 0.6386139030361934
Loss in iteration 9 : 0.6265025950241776
Loss in iteration 10 : 0.6140543387298301
Loss in iteration 11 : 0.6014573954398191
Loss in iteration 12 : 0.5888739112562951
Loss in iteration 13 : 0.5764405595815909
Loss in iteration 14 : 0.5642697777179729
Loss in iteration 15 : 0.5524514611128434
Loss in iteration 16 : 0.5410549819138885
Loss in iteration 17 : 0.530131406341981
Loss in iteration 18 : 0.5197157979938284
Loss in iteration 19 : 0.5098295106594727
Loss in iteration 20 : 0.5004823931136286
Testing accuracy  of updater 1 on alg 0 with rate 0.09999999999999998 = 0.906527207732027, training accuracy 0.8666444407401234, time elapsed: 6748 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.409281814150818
Loss in iteration 3 : 0.36821289178019195
Loss in iteration 4 : 0.3761910764578471
Loss in iteration 5 : 0.39348663427783154
Loss in iteration 6 : 0.40730440215701136
Loss in iteration 7 : 0.413459813680717
Loss in iteration 8 : 0.411339227838494
Loss in iteration 9 : 0.4021202996634265
Loss in iteration 10 : 0.38806783885209345
Loss in iteration 11 : 0.3721416241835843
Loss in iteration 12 : 0.3575193744092622
Loss in iteration 13 : 0.3468204214902118
Loss in iteration 14 : 0.34114490307347056
Loss in iteration 15 : 0.33949595970751084
Loss in iteration 16 : 0.3392662940792457
Loss in iteration 17 : 0.33785306152476263
Loss in iteration 18 : 0.33431914417146513
Loss in iteration 19 : 0.32957178475795307
Loss in iteration 20 : 0.3250806892951248
Testing accuracy  of updater 2 on alg 0 with rate 10.0 = 0.9059976168409903, training accuracy 0.8744790798466411, time elapsed: 7697 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6467695943425618
Loss in iteration 3 : 0.5918931843783274
Loss in iteration 4 : 0.5374851311728941
Loss in iteration 5 : 0.48950505371919734
Loss in iteration 6 : 0.4506293513631085
Loss in iteration 7 : 0.4210881754507564
Loss in iteration 8 : 0.39979434907230826
Loss in iteration 9 : 0.38519836627881765
Loss in iteration 10 : 0.3757576117469019
Loss in iteration 11 : 0.3701310413503572
Loss in iteration 12 : 0.36722836584286317
Loss in iteration 13 : 0.36619636053780574
Loss in iteration 14 : 0.36638391319800623
Loss in iteration 15 : 0.3673039132646609
Loss in iteration 16 : 0.3685988125749629
Loss in iteration 17 : 0.37001179424220026
Loss in iteration 18 : 0.3713635308743196
Loss in iteration 19 : 0.3725338294356333
Loss in iteration 20 : 0.37344730335774834
Testing accuracy  of updater 2 on alg 0 with rate 1.0 = 0.906527207732027, training accuracy 0.8698116352725455, time elapsed: 6298 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6883053829791589
Loss in iteration 3 : 0.6815223698207328
Loss in iteration 4 : 0.6731144250483428
Loss in iteration 5 : 0.6633853368135687
Loss in iteration 6 : 0.6526207828614349
Loss in iteration 7 : 0.6410842853116125
Loss in iteration 8 : 0.6290145107256732
Loss in iteration 9 : 0.6166237268130518
Loss in iteration 10 : 0.6040972490637716
Loss in iteration 11 : 0.5915937222582792
Loss in iteration 12 : 0.5792460873306937
Loss in iteration 13 : 0.5671630874973983
Loss in iteration 14 : 0.5554311721673041
Loss in iteration 15 : 0.5441166650080742
Loss in iteration 16 : 0.533268074471764
Loss in iteration 17 : 0.522918440795304
Loss in iteration 18 : 0.5130876319170296
Loss in iteration 19 : 0.503784520427166
Loss in iteration 20 : 0.4950089930972531
Testing accuracy  of updater 2 on alg 0 with rate 0.09999999999999998 = 0.906527207732027, training accuracy 0.8668111351891982, time elapsed: 7540 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 2.874685759931431
Loss in iteration 3 : 1.1293764850260848
Loss in iteration 4 : 0.5464668599110474
Loss in iteration 5 : 0.3528396824568507
Loss in iteration 6 : 0.26647199001009503
Loss in iteration 7 : 0.2564275466597658
Loss in iteration 8 : 0.29167370295705725
Loss in iteration 9 : 0.40893702682378463
Loss in iteration 10 : 0.21788585363393248
Loss in iteration 11 : 0.21179560102768652
Loss in iteration 12 : 0.19221468234342184
Loss in iteration 13 : 0.2336169872922377
Loss in iteration 14 : 0.18493403194183994
Loss in iteration 15 : 0.21148164343108908
Loss in iteration 16 : 0.17848299330309483
Loss in iteration 17 : 0.21089075294699336
Loss in iteration 18 : 0.16535901035000797
Loss in iteration 19 : 0.18193838138112567
Loss in iteration 20 : 0.1603342211796636
Testing accuracy  of updater 3 on alg 0 with rate 10.0 = 0.8698530385277373, training accuracy 0.9401566927821303, time elapsed: 7531 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.33384802988236684
Loss in iteration 3 : 0.30037225140514545
Loss in iteration 4 : 0.2790082807391094
Loss in iteration 5 : 0.26348193472523945
Loss in iteration 6 : 0.25140729962163205
Loss in iteration 7 : 0.24161401826543116
Loss in iteration 8 : 0.23343807954059043
Loss in iteration 9 : 0.2264654823894663
Loss in iteration 10 : 0.22042055469131544
Loss in iteration 11 : 0.2151105995158639
Loss in iteration 12 : 0.21039577281233598
Loss in iteration 13 : 0.20617150001215587
Loss in iteration 14 : 0.20235763649688615
Loss in iteration 15 : 0.19889148643018426
Loss in iteration 16 : 0.19572314146279218
Loss in iteration 17 : 0.19281227251459757
Loss in iteration 18 : 0.19012586358382885
Loss in iteration 19 : 0.1876365745522702
Loss in iteration 20 : 0.18532153487980788
Testing accuracy  of updater 3 on alg 0 with rate 1.0 = 0.8796504700119158, training accuracy 0.9353225537589598, time elapsed: 6915 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6391709597012483
Loss in iteration 3 : 0.5984443684611864
Loss in iteration 4 : 0.566144944523902
Loss in iteration 5 : 0.5396915230377822
Loss in iteration 6 : 0.5175226472192974
Loss in iteration 7 : 0.4986164310314463
Loss in iteration 8 : 0.4822662926654439
Loss in iteration 9 : 0.4679633531877953
Loss in iteration 10 : 0.4553294039155711
Loss in iteration 11 : 0.44407620852030977
Loss in iteration 12 : 0.433979540890819
Loss in iteration 13 : 0.42486195042918773
Loss in iteration 14 : 0.4165809400136359
Loss in iteration 15 : 0.4090206313247308
Loss in iteration 16 : 0.40208575032430155
Loss in iteration 17 : 0.39569719916487
Loss in iteration 18 : 0.3897887387632726
Loss in iteration 19 : 0.38430446513030575
Loss in iteration 20 : 0.37919686333981073
Testing accuracy  of updater 3 on alg 0 with rate 0.09999999999999998 = 0.9059976168409903, training accuracy 0.879979996666111, time elapsed: 8375 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6928432347460195
Loss in iteration 3 : 0.6925323472610608
Loss in iteration 4 : 0.6922167421591587
Loss in iteration 5 : 0.6918975350766723
Loss in iteration 6 : 0.6915753950619822
Loss in iteration 7 : 0.6912507669990959
Loss in iteration 8 : 0.6909239674172363
Loss in iteration 9 : 0.6905952325569235
Loss in iteration 10 : 0.6902647451359727
Loss in iteration 11 : 0.6899326504365519
Loss in iteration 12 : 0.6895990665556233
Loss in iteration 13 : 0.6892640912455549
Loss in iteration 14 : 0.6889278066537953
Loss in iteration 15 : 0.6885902827106319
Loss in iteration 16 : 0.6882515796148594
Loss in iteration 17 : 0.6879117496987673
Loss in iteration 18 : 0.6875708388546862
Loss in iteration 19 : 0.6872288876445659
Loss in iteration 20 : 0.6868859321758392
Testing accuracy  of updater 4 on alg 0 with rate 10.0 = 0.906527207732027, training accuracy 0.8669778296382731, time elapsed: 7672 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6928432347460195
Loss in iteration 3 : 0.6925323472610608
Loss in iteration 4 : 0.6922167421591587
Loss in iteration 5 : 0.6918975350766723
Loss in iteration 6 : 0.6915753950619822
Loss in iteration 7 : 0.6912507669990959
Loss in iteration 8 : 0.6909239674172363
Loss in iteration 9 : 0.6905952325569235
Loss in iteration 10 : 0.6902647451359727
Loss in iteration 11 : 0.6899326504365519
Loss in iteration 12 : 0.6895990665556233
Loss in iteration 13 : 0.6892640912455549
Loss in iteration 14 : 0.6889278066537953
Loss in iteration 15 : 0.6885902827106319
Loss in iteration 16 : 0.6882515796148594
Loss in iteration 17 : 0.6879117496987673
Loss in iteration 18 : 0.6875708388546862
Loss in iteration 19 : 0.6872288876445659
Loss in iteration 20 : 0.6868859321758392
Testing accuracy  of updater 4 on alg 0 with rate 1.0 = 0.906527207732027, training accuracy 0.8669778296382731, time elapsed: 8606 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6928432347460195
Loss in iteration 3 : 0.6925323472610608
Loss in iteration 4 : 0.6922167421591587
Loss in iteration 5 : 0.6918975350766723
Loss in iteration 6 : 0.6915753950619822
Loss in iteration 7 : 0.6912507669990959
Loss in iteration 8 : 0.6909239674172363
Loss in iteration 9 : 0.6905952325569235
Loss in iteration 10 : 0.6902647451359727
Loss in iteration 11 : 0.6899326504365519
Loss in iteration 12 : 0.6895990665556233
Loss in iteration 13 : 0.6892640912455549
Loss in iteration 14 : 0.6889278066537953
Loss in iteration 15 : 0.6885902827106319
Loss in iteration 16 : 0.6882515796148594
Loss in iteration 17 : 0.6879117496987673
Loss in iteration 18 : 0.6875708388546862
Loss in iteration 19 : 0.6872288876445659
Loss in iteration 20 : 0.6868859321758392
Testing accuracy  of updater 4 on alg 0 with rate 0.09999999999999998 = 0.906527207732027, training accuracy 0.8669778296382731, time elapsed: 7106 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 8.251590726270473
Loss in iteration 3 : 3.3659122146227003
Loss in iteration 4 : 1.7189677773191874
Loss in iteration 5 : 1.2154025926680254
Loss in iteration 6 : 1.1677974234544286
Loss in iteration 7 : 1.6728389590320252
Loss in iteration 8 : 0.8607212820341986
Loss in iteration 9 : 1.1690523318245305
Loss in iteration 10 : 0.8743306952697653
Loss in iteration 11 : 1.4789567818386173
Loss in iteration 12 : 0.5642127164817555
Loss in iteration 13 : 0.5899120836194088
Loss in iteration 14 : 0.6402783692740319
Loss in iteration 15 : 1.3462026636942894
Loss in iteration 16 : 0.6282697187733813
Loss in iteration 17 : 0.8798720412564851
Loss in iteration 18 : 0.8097289601862017
Loss in iteration 19 : 1.5566589770091193
Loss in iteration 20 : 0.5962478312784524
Testing accuracy  of updater 5 on alg 0 with rate 10.0 = 0.8634979478352972, training accuracy 0.9418236372728788, time elapsed: 6784 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6052296171704078
Loss in iteration 3 : 0.31524537422005405
Loss in iteration 4 : 0.2418429378648314
Loss in iteration 5 : 0.21372759437861963
Loss in iteration 6 : 0.1985409737045372
Loss in iteration 7 : 0.1888976015793882
Loss in iteration 8 : 0.18204100858241537
Loss in iteration 9 : 0.17660279953093233
Loss in iteration 10 : 0.17202793800686525
Loss in iteration 11 : 0.16804862250784158
Loss in iteration 12 : 0.1645342412351984
Loss in iteration 13 : 0.1614056207912404
Loss in iteration 14 : 0.15861194072860255
Loss in iteration 15 : 0.15614868072039656
Loss in iteration 16 : 0.15403056646992486
Loss in iteration 17 : 0.15248206669391678
Loss in iteration 18 : 0.15180343463352572
Loss in iteration 19 : 0.1538336889006004
Loss in iteration 20 : 0.15950297005395667
Testing accuracy  of updater 5 on alg 0 with rate 1.0 = 0.8907718787236859, training accuracy 0.923320553425571, time elapsed: 6861 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.4764121449539174
Loss in iteration 3 : 0.40557430879283946
Loss in iteration 4 : 0.36989925778378857
Loss in iteration 5 : 0.34756296597230213
Loss in iteration 6 : 0.3316789103098346
Loss in iteration 7 : 0.31944078034102796
Loss in iteration 8 : 0.3094999931072936
Loss in iteration 9 : 0.30112696149831775
Loss in iteration 10 : 0.29388949284881094
Loss in iteration 11 : 0.2875125093282972
Loss in iteration 12 : 0.2818105668108468
Loss in iteration 13 : 0.27665273901528414
Loss in iteration 14 : 0.2719430953018197
Loss in iteration 15 : 0.26760920804469285
Loss in iteration 16 : 0.2635950398381411
Loss in iteration 17 : 0.2598563461229571
Loss in iteration 18 : 0.25635759126372176
Loss in iteration 19 : 0.2530698137692048
Loss in iteration 20 : 0.24996910865671046
Testing accuracy  of updater 5 on alg 0 with rate 0.09999999999999998 = 0.893949424069906, training accuracy 0.903817302883814, time elapsed: 6738 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.4534229004095841
Loss in iteration 3 : 0.49104719315208234
Loss in iteration 4 : 0.4164854231636404
Loss in iteration 5 : 0.3290323845800378
Loss in iteration 6 : 0.2927068508847689
Loss in iteration 7 : 0.30075479427455126
Loss in iteration 8 : 0.3031658603424332
Loss in iteration 9 : 0.2752676657992878
Loss in iteration 10 : 0.23344940243532528
Loss in iteration 11 : 0.20328720676382653
Loss in iteration 12 : 0.1942750635490446
Loss in iteration 13 : 0.1975007734112599
Loss in iteration 14 : 0.19932514799151443
Loss in iteration 15 : 0.19248882334248044
Loss in iteration 16 : 0.1781980104919568
Loss in iteration 17 : 0.1633860826492474
Loss in iteration 18 : 0.15560629973296547
Loss in iteration 19 : 0.1559881395981029
Loss in iteration 20 : 0.15772373324861805
Testing accuracy  of updater 6 on alg 0 with rate 2.0 = 0.8057725407122998, training accuracy 0.9348224704117353, time elapsed: 6933 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6186988192408402
Loss in iteration 3 : 0.5230279117758942
Loss in iteration 4 : 0.4348038540093214
Loss in iteration 5 : 0.3682147990510679
Loss in iteration 6 : 0.32541352249434885
Loss in iteration 7 : 0.3013696958895325
Loss in iteration 8 : 0.2890921054348913
Loss in iteration 9 : 0.2827088558614633
Loss in iteration 10 : 0.2783210082601377
Loss in iteration 11 : 0.27374452954912154
Loss in iteration 12 : 0.2679895617065397
Loss in iteration 13 : 0.2608143786334537
Loss in iteration 14 : 0.2524140273112504
Loss in iteration 15 : 0.24321486208748533
Loss in iteration 16 : 0.23373650752871541
Loss in iteration 17 : 0.22449450714560687
Loss in iteration 18 : 0.21592957805238716
Loss in iteration 19 : 0.20835828209905796
Loss in iteration 20 : 0.20194495700942397
Testing accuracy  of updater 6 on alg 0 with rate 0.2 = 0.8661459022904806, training accuracy 0.9214869144857476, time elapsed: 6707 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6866011777424714
Loss in iteration 3 : 0.6754010299240377
Loss in iteration 4 : 0.660811632705792
Loss in iteration 5 : 0.6438233002730548
Loss in iteration 6 : 0.6252260261321939
Loss in iteration 7 : 0.605655484193327
Loss in iteration 8 : 0.5856237494667677
Loss in iteration 9 : 0.5655411413454461
Loss in iteration 10 : 0.5457326393199372
Loss in iteration 11 : 0.5264508497157697
Loss in iteration 12 : 0.5078867038475313
Loss in iteration 13 : 0.4901786042077097
Loss in iteration 14 : 0.47342045197056154
Loss in iteration 15 : 0.4576688110300879
Loss in iteration 16 : 0.4429493516646753
Loss in iteration 17 : 0.4292626484436344
Loss in iteration 18 : 0.4165893683222248
Loss in iteration 19 : 0.4048948665741194
Loss in iteration 20 : 0.3941332033567336
Testing accuracy  of updater 6 on alg 0 with rate 0.01999999999999999 = 0.905732821395472, training accuracy 0.879979996666111, time elapsed: 6923 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : NaN
Loss in iteration 3 : NaN
Loss in iteration 4 : NaN
Loss in iteration 5 : NaN
Loss in iteration 6 : NaN
Loss in iteration 7 : NaN
Loss in iteration 8 : NaN
Loss in iteration 9 : NaN
Loss in iteration 10 : NaN
Loss in iteration 11 : NaN
Loss in iteration 12 : NaN
Loss in iteration 13 : NaN
Loss in iteration 14 : NaN
Loss in iteration 15 : NaN
Loss in iteration 16 : NaN
Loss in iteration 17 : NaN
Loss in iteration 18 : NaN
Loss in iteration 19 : NaN
Loss in iteration 20 : NaN
Testing accuracy  of updater 7 on alg 0 with rate 20.0 = 0.09347279226797299, training accuracy 0.13335555925987663, time elapsed: 7754 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : NaN
Loss in iteration 3 : NaN
Loss in iteration 4 : NaN
Loss in iteration 5 : NaN
Loss in iteration 6 : NaN
Loss in iteration 7 : NaN
Loss in iteration 8 : NaN
Loss in iteration 9 : NaN
Loss in iteration 10 : NaN
Loss in iteration 11 : NaN
Loss in iteration 12 : NaN
Loss in iteration 13 : NaN
Loss in iteration 14 : NaN
Loss in iteration 15 : NaN
Loss in iteration 16 : NaN
Loss in iteration 17 : NaN
Loss in iteration 18 : NaN
Loss in iteration 19 : NaN
Loss in iteration 20 : NaN
Testing accuracy  of updater 7 on alg 0 with rate 2.0 = 0.09347279226797299, training accuracy 0.13335555925987663, time elapsed: 8969 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : NaN
Loss in iteration 3 : NaN
Loss in iteration 4 : NaN
Loss in iteration 5 : NaN
Loss in iteration 6 : NaN
Loss in iteration 7 : NaN
Loss in iteration 8 : NaN
Loss in iteration 9 : NaN
Loss in iteration 10 : NaN
Loss in iteration 11 : NaN
Loss in iteration 12 : NaN
Loss in iteration 13 : NaN
Loss in iteration 14 : NaN
Loss in iteration 15 : NaN
Loss in iteration 16 : NaN
Loss in iteration 17 : NaN
Loss in iteration 18 : NaN
Loss in iteration 19 : NaN
Loss in iteration 20 : NaN
Testing accuracy  of updater 7 on alg 0 with rate 0.19999999999999996 = 0.09347279226797299, training accuracy 0.13335555925987663, time elapsed: 8298 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.7085809673854341
Loss in iteration 3 : 0.5041219440819015
Loss in iteration 4 : 0.35031157629181015
Loss in iteration 5 : 0.2720862798972294
Loss in iteration 6 : 0.24893570476300975
Loss in iteration 7 : 0.23148480837859223
Loss in iteration 8 : 0.20849363276017183
Loss in iteration 9 : 0.18811112214629064
Loss in iteration 10 : 0.17399265957392343
Loss in iteration 11 : 0.16428963000774954
Loss in iteration 12 : 0.15631985540069146
Loss in iteration 13 : 0.1490194462435159
Loss in iteration 14 : 0.14265003114701316
Loss in iteration 15 : 0.1375921996554497
Loss in iteration 16 : 0.13368812374101663
Loss in iteration 17 : 0.1304619375402254
Loss in iteration 18 : 0.1275822692940086
Loss in iteration 19 : 0.12494861825056512
Loss in iteration 20 : 0.1225446109357565
Testing accuracy  of updater 8 on alg 0 with rate 2.0 = 0.827220971799285, training accuracy 0.9491581930321721, time elapsed: 8147 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.560225261283462
Loss in iteration 3 : 0.4541969878715908
Loss in iteration 4 : 0.38004609117688426
Loss in iteration 5 : 0.3329036147682904
Loss in iteration 6 : 0.3043928206545545
Loss in iteration 7 : 0.2869112092248866
Loss in iteration 8 : 0.2751027177342374
Loss in iteration 9 : 0.2657373174667239
Loss in iteration 10 : 0.2571216272237579
Loss in iteration 11 : 0.24854100220508343
Loss in iteration 12 : 0.23985163889801975
Loss in iteration 13 : 0.2312058940255265
Loss in iteration 14 : 0.22287108841566344
Loss in iteration 15 : 0.21511216941103847
Loss in iteration 16 : 0.20812139740826843
Loss in iteration 17 : 0.20198579476170397
Loss in iteration 18 : 0.1966854274726479
Loss in iteration 19 : 0.1921147722455374
Loss in iteration 20 : 0.18811773140710758
Testing accuracy  of updater 8 on alg 0 with rate 0.2 = 0.8605851979345955, training accuracy 0.9306551091848642, time elapsed: 7450 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6790843295620171
Loss in iteration 3 : 0.6618005320641316
Loss in iteration 4 : 0.642451454591346
Loss in iteration 5 : 0.6218875577995123
Loss in iteration 6 : 0.6007528406241045
Loss in iteration 7 : 0.5795402723231248
Loss in iteration 8 : 0.5586264517077097
Loss in iteration 9 : 0.5382952473002726
Loss in iteration 10 : 0.5187551347387472
Loss in iteration 11 : 0.5001526929110016
Loss in iteration 12 : 0.4825836082903525
Loss in iteration 13 : 0.4661019477955405
Loss in iteration 14 : 0.45072813338325163
Loss in iteration 15 : 0.4364558662583921
Loss in iteration 16 : 0.4232581447076512
Loss in iteration 17 : 0.411092464212138
Loss in iteration 18 : 0.3999052622727839
Loss in iteration 19 : 0.3896356611102501
Loss in iteration 20 : 0.3802185611550002
Testing accuracy  of updater 8 on alg 0 with rate 0.01999999999999999 = 0.905732821395472, training accuracy 0.8798133022170361, time elapsed: 8690 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 1.8286108297803771
Loss in iteration 3 : 1.982813394941708
Loss in iteration 4 : 1.5559541973017137
Loss in iteration 5 : 1.204489372661788
Loss in iteration 6 : 1.249224218833246
Loss in iteration 7 : 1.3259665277117978
Loss in iteration 8 : 1.147586546834683
Loss in iteration 9 : 0.8994236702694947
Loss in iteration 10 : 0.7954507473479975
Loss in iteration 11 : 0.8242339341832985
Loss in iteration 12 : 0.8479554140813672
Loss in iteration 13 : 0.7865389533181399
Loss in iteration 14 : 0.6703407569608795
Loss in iteration 15 : 0.5961726633081952
Loss in iteration 16 : 0.5956907617851508
Loss in iteration 17 : 0.5937760252890965
Loss in iteration 18 : 0.5274536866437082
Loss in iteration 19 : 0.4606610886644716
Loss in iteration 20 : 0.4410521711869663
Testing accuracy  of updater 9 on alg 0 with rate 2.0 = 0.8278829604130808, training accuracy 0.942657109518253, time elapsed: 8646 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.37948752242410594
Loss in iteration 3 : 0.29881525292067257
Loss in iteration 4 : 0.31266821821098284
Loss in iteration 5 : 0.317659979934405
Loss in iteration 6 : 0.3000016292056078
Loss in iteration 7 : 0.26910898223062135
Loss in iteration 8 : 0.23877179326905396
Loss in iteration 9 : 0.21937399809885272
Loss in iteration 10 : 0.2128050377189024
Loss in iteration 11 : 0.21246998517715981
Loss in iteration 12 : 0.20947485281076691
Loss in iteration 13 : 0.19927022964621235
Loss in iteration 14 : 0.18346230691493476
Loss in iteration 15 : 0.16713808779625774
Loss in iteration 16 : 0.1549002862141881
Loss in iteration 17 : 0.14839016563551738
Loss in iteration 18 : 0.14631789612285903
Loss in iteration 19 : 0.14607487751286538
Loss in iteration 20 : 0.14535661675024591
Testing accuracy  of updater 9 on alg 0 with rate 0.2 = 0.8539653117966371, training accuracy 0.9421570261710285, time elapsed: 7879 millisecond.
Loss in iteration 1 : 0.6931471805599078
Loss in iteration 2 : 0.6569035706956321
Loss in iteration 3 : 0.6022360317788674
Loss in iteration 4 : 0.5412063655453827
Loss in iteration 5 : 0.4821716582194581
Loss in iteration 6 : 0.43023528301660124
Loss in iteration 7 : 0.3877276817566883
Loss in iteration 8 : 0.35487537732506846
Loss in iteration 9 : 0.3305813279569102
Loss in iteration 10 : 0.31314043259599184
Loss in iteration 11 : 0.3007591148925663
Loss in iteration 12 : 0.2918507044400464
Loss in iteration 13 : 0.285153040683631
Loss in iteration 14 : 0.27973691500358977
Loss in iteration 15 : 0.2749623891815104
Loss in iteration 16 : 0.2704188770357766
Loss in iteration 17 : 0.2658671809219551
Loss in iteration 18 : 0.261190576338284
Loss in iteration 19 : 0.25635629725005304
Loss in iteration 20 : 0.25138633551877965
Testing accuracy  of updater 9 on alg 0 with rate 0.01999999999999999 = 0.8988481398119952, training accuracy 0.8958159693282214, time elapsed: 7331 millisecond.
